# -*- coding: utf-8 -*-
"""final code for segmentation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12dKHaFJvxDHq4q_R1q_1XRQCx57FRJcT
"""

# We need to link this collab to googgle drive where dataset is saved
from google.colab import drive
drive.mount('/content/drive')

import os

# Define paths
image_dir = "/content/drive/MyDrive/resized_image/images"  # Update wthis path with your actual saved path
mask_dir = "/content/drive/MyDrive/resized_image/masks"
# Get list of files in each directory
image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]
mask_paths = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]

# Print the counts
print(f"Number of images: {len(image_paths)}")
print(f"Number of masks: {len(mask_paths)}")

# We need to check that all images are having corresponding masks
import os

# Define paths (update with actual paths)
image_dir = "/content/drive/MyDrive/resized_image/images"  # Update with actual path
mask_dir = "/content/drive/MyDrive/resized_image/masks"
# Get list of image and mask filenames (without extensions)
image_filenames = {os.path.splitext(f)[0] for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))}
mask_filenames = {os.path.splitext(f)[0] for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))}

# Find images without corresponding masks
missing_masks = image_filenames - mask_filenames  # Set difference

# Print images missing masks
if missing_masks:
    print("Images without corresponding masks:")
    for img in missing_masks:
        print(img)
else:
    print("All images have corresponding masks.")

#plotting a 5 random images with their corresponding  masks
import os
import cv2
import matplotlib.pyplot as plt
import random

# Define paths (update with actual paths)
image_dir = "/content/drive/MyDrive/resized_image/images"  # Update with actual path
mask_dir = "/content/drive/MyDrive/resized_image/masks"
# Get list of image filenames (ensuring corresponding masks exist)
image_filenames = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]
mask_filenames = {os.path.splitext(f)[0] for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))}

# Filter images that have corresponding masks
valid_images = [img for img in image_filenames if os.path.splitext(img)[0] in mask_filenames]

# Select 5 random images
random_images = random.sample(valid_images, min(5, len(valid_images)))


# Plot images and masks
fig, axes = plt.subplots(len(random_images), 2, figsize=(10, 10))

for i, img_name in enumerate(random_images):
    img_path = os.path.join(image_dir, img_name)
    mask_path = os.path.join(mask_dir, os.path.splitext(img_name)[0] + ".png")  # Ensure mask extension matches

    # Read image and mask
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct color representation
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Read mask as grayscale

    # Display image
    axes[i, 0].imshow(img)
    axes[i, 0].set_title(f"Image: {img_name}")
    axes[i, 0].axis("off")

    # Display corresponding mask
    axes[i, 1].imshow(mask, cmap="gray")
    axes[i, 1].set_title(f"Mask: {os.path.basename(mask_path)}")
    axes[i, 1].axis("off")

plt.tight_layout()
plt.show()

#This piece of code is for manual splitting,in case the dataset is not splitted into train and validation
import os
import shutil
import random

# Paths
source_dir = "/content/drive/MyDrive/resized_image"
dest_dir = "/content/drive/MyDrive/Dataset"

# Create target folders
for split in ['train', 'val', 'test']:
    for sub in ['images', 'masks']:
        os.makedirs(os.path.join(dest_dir, split, sub), exist_ok=True)

# Get image and mask files
images = sorted([f for f in os.listdir(os.path.join(source_dir, "images")) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
masks = sorted([f for f in os.listdir(os.path.join(source_dir, "masks")) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

# Ensure same number of images and masks
if len(images) != len(masks):
    raise ValueError("Number of images and masks do not match!")

# Shuffle
combined = list(zip(images, masks))
random.shuffle(combined)

# Split sizes
total = len(combined)
train_size = int(0.6 * total)   # 3/5 = 0.6
val_size = int(0.2 * total)     # 1/5 = 0.2
test_size = total - train_size - val_size

# Split dataset
train_data = combined[:train_size]
val_data = combined[train_size:train_size + val_size]
test_data = combined[train_size + val_size:]

def copy_files(data, split):
    for img, mask in data:
        shutil.copy(os.path.join(source_dir, "images", img), os.path.join(dest_dir, split, "images", img))
        shutil.copy(os.path.join(source_dir, "masks", mask), os.path.join(dest_dir, split, "masks", mask))

copy_files(train_data, "train")
copy_files(val_data, "val")
copy_files(test_data, "test")

print("Dataset split completed successfully!")

#length of masks and images in the tarin,test,validation

import os

# Define paths to the dataset splits
dataset_dir = "/content/drive/MyDrive/Dataset"
splits = ["train", "val", "test"]

for split in splits:
    image_dir = os.path.join(dataset_dir, split, "images")
    mask_dir = os.path.join(dataset_dir, split, "masks")

    num_images = len(os.listdir(image_dir))
    num_masks = len(os.listdir(mask_dir))

    print(f"Split: {split}")
    print(f"  Number of images: {num_images}")
    print(f"  Number of masks: {num_masks}")

from IPython import get_ipython
from IPython.display import display
from google.colab import drive
import os
import numpy as np
from matplotlib import pyplot as plt
import cv2
from PIL import Image, ImageOps
import tensorflow as tf
import tensorflow.keras.backend as K
from sklearn.model_selection import train_test_split

# Mount Google Drive
drive.mount('/content/drive/')

# Define paths
train_path="/content/drive/MyDrive/Dataset/train"
test_path="/content/drive/MyDrive/Dataset/test"
val_path="/content/drive/MyDrive/Dataset/val"

train_img_path = os.path.join(train_path, "images")
train_mask_path = os.path.join(train_path, "masks")
test_img_path = os.path.join(test_path, "images")
test_mask_path = os.path.join(test_path, "masks")
val_img_path = os.path.join(val_path, "images")
val_mask_path = os.path.join(val_path, "masks")

# Sort image and mask filenames
train_images = sorted(os.listdir(train_img_path))
train_masks = sorted(os.listdir(train_mask_path))
test_images = sorted(os.listdir(test_img_path))
test_masks = sorted(os.listdir(test_mask_path))
val_images = sorted(os.listdir(val_img_path))
val_masks = sorted(os.listdir(val_mask_path))

# Convert filenames to full paths
train_images = [os.path.join(train_img_path, img) for img in train_images]
train_masks = [os.path.join(train_mask_path, mask) for mask in train_masks]
test_images = [os.path.join(test_img_path, img) for img in test_images]
test_masks = [os.path.join(test_mask_path, mask) for mask in test_masks]
val_images = [os.path.join(val_img_path, img) for img in val_images]
val_masks = [os.path.join(val_mask_path, mask) for mask in val_masks]

print(train_images[:5])

print("Train Images:", len(train_images), "| Masks:", len(train_masks))
print("Test Images:", len(test_images), "| Masks:", len(test_masks))
print("Validation Images:", len(val_images), "| Masks:", len(val_masks))

# Function to load and preprocess images & masks
def load_images_and_masks(image_paths, mask_paths, img_size=(256, 256), binary_threshold=125):
    images = []
    masks = []

    # remove bad data before processing
    valid_indices = []
    for i, (img_path, mask_path) in enumerate(zip(image_paths, mask_paths)):
        img = cv2.imread(img_path)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if img is not None and mask is not None:
            valid_indices.append(i)
        else:
            if img is None:
                print(f"Warning: Image not found {img_path}")
            if mask is None:
                print(f"Warning: Mask not found {mask_path}")

    image_paths = [image_paths[i] for i in valid_indices]
    mask_paths = [mask_paths[i] for i in valid_indices]

    for img_path, mask_path in zip(image_paths, mask_paths):
        # Read and preprocess image
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB
        img = cv2.resize(img, img_size)  # Resize image
        images.append(img)

        # Read and preprocess mask
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, img_size)  # Resize mask
        mask = np.array(mask > binary_threshold, dtype=np.uint8)  # Convert to binary mask
        masks.append(mask)

    return np.array(images), np.array(masks)

# Load train, test, and validation
X_train, Y_train = load_images_and_masks(train_images, train_masks)
X_test, Y_test = load_images_and_masks(test_images, test_masks)
X_val, Y_val = load_images_and_masks(val_images, val_masks)

# Expand dimensions
Y_train = np.expand_dims(Y_train, axis=-1)
Y_test = np.expand_dims(Y_test, axis=-1)
Y_val = np.expand_dims(Y_val, axis=-1)

print("Train set:", X_train.shape, Y_train.shape)
print("Test set:", X_test.shape, Y_test.shape)
print("Validation set:", X_val.shape, Y_val.shape)

def prepare_data(x, y, shuffle=False):
    x = np.array(x, dtype=np.float32)  # Ensure float32
    y = np.array(y, dtype=np.float32)

    data = tf.data.Dataset.from_tensor_slices((x, y))
    data = data.shuffle(buffer_size=1540)  # Shuffle before batching
    data = data.batch(16)
    data = data.cache()
    data = data.prefetch(buffer_size=tf.data.AUTOTUNE)
    return data

train_data = prepare_data(X_train, Y_train,shuffle=True)
test_data = prepare_data(X_test, Y_test,shuffle=False)
val_data = prepare_data(X_val, Y_val,shuffle=False)

train_data.take(1)

#Actual model that trains the images
import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import (
    Input, Conv2D, BatchNormalization,
    Activation, UpSampling2D, concatenate
)
from tensorflow.keras.models import Model

def simple_conv_block(x, filters, kernel_size=3, activation='relu'):
    """
    A simplified convolutional block used in the decoder.
    Each block consists of a convolution, batch normalization, and an activation function.
    """
    x = Conv2D(filters, kernel_size, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = Activation(activation)(x)
    return x

def create_lightweight_unet(input_shape=(256, 256, 3)):
    """
    Creates a lightweight U-Net model with a pre-trained EfficientNetB0 encoder.
    The decoder has been simplified to reduce the total number of trainable parameters.
    This version uses a corrected set of skip connections to resolve shape mismatches.
    """
    inputs = Input(input_shape)

    # ðŸ”¹ Encoder: EfficientNetB0 (pre-trained on ImageNet)
    # We use a pre-trained encoder for powerful feature extraction (transfer learning).
    encoder = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=inputs)

    # Optional: To make the model even lighter and train faster, you can freeze the encoder.
    # This means the weights of the pre-trained layers will not be updated during training.
    # encoder.trainable = False

    # ðŸ”¹ Skip Connections from key points in the encoder
    # These connections feed spatial information from the encoder directly to the decoder,
    # which is crucial for precise segmentation. We pick layers just before downsampling.
    s1 = encoder.get_layer("block2a_expand_activation").output # 128x128
    s2 = encoder.get_layer("block3a_expand_activation").output # 64x64
    s3 = encoder.get_layer("block4a_expand_activation").output # 32x32
    s4 = encoder.get_layer("block6a_expand_activation").output # 16x16

    # ðŸ”¹ Bottleneck: The bridge between the encoder and decoder.
    # This is the deepest point in the network.
    b1 = encoder.get_layer("top_activation").output # 8x8

    # ðŸ”¹ Decoder: The upsampling path
    # Each block upsamples the feature map and concatenates it with a skip connection
    # from the corresponding level in the encoder.
    d1 = UpSampling2D((2, 2))(b1)
    d1 = concatenate([d1, s4])
    d1 = simple_conv_block(d1, 128)

    d2 = UpSampling2D((2, 2))(d1)
    d2 = concatenate([d2, s3])
    d2 = simple_conv_block(d2, 64)

    d3 = UpSampling2D((2, 2))(d2)
    d3 = concatenate([d3, s2])
    d3 = simple_conv_block(d3, 32)

    d4 = UpSampling2D((2, 2))(d3)
    d4 = concatenate([d4, s1])
    d4 = simple_conv_block(d4, 16)

    # Final upsampling to the original image size
    d5 = UpSampling2D((2, 2))(d4)
    d5 = simple_conv_block(d5, 8)

    # ðŸ”¹ Output Layer
    # A 1x1 convolution with a sigmoid activation produces the final
    # binary segmentation map (pixel values between 0 and 1).
    outputs = Conv2D(1, kernel_size=1, activation='sigmoid')(d5)

    model = Model(inputs=inputs, outputs=outputs, name="Lightweight_EfficientNetB0_UNet_Fixed")
    return model

# Create and summarize the new, fixed model
model2 = create_lightweight_unet()
model2.summary()

#Defining the metrics
import tensorflow.keras.backend as K
import tensorflow as tf

# Dice Coefficient
def dice_coef(y_true, y_pred, smooth=1e-7):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

# Sensitivity (Recall)
def sensitivity(y_true, y_pred):
    tp = K.sum(y_true * y_pred)
    fn = K.sum(y_true * (1 - y_pred))
    return tp / (tp + fn + K.epsilon())

# Specificity
def specificity(y_true, y_pred):
    tn = K.sum((1 - y_true) * (1 - y_pred))
    fp = K.sum((1 - y_true) * y_pred)
    return tn / (tn + fp + K.epsilon())
# Mean Intersection over Union (mIoU)
def mean_iou(y_true, y_pred, num_classes=2):
    y_pred = K.round(y_pred)  # Ensure binary predictions for IoU calculation
    iou = []

    for i in range(num_classes):
        true_class = K.cast(K.equal(y_true, i), K.floatx())
        pred_class = K.cast(K.equal(y_pred, i), K.floatx())

        intersection = K.sum(true_class * pred_class)
        union = K.sum(true_class) + K.sum(pred_class) - intersection

        iou.append((intersection + K.epsilon()) / (union + K.epsilon()))

    return K.mean(K.stack(iou))

#Compile the model
model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', dice_coef, sensitivity, specificity])

# Train the model (50)
history = model2.fit(train_data, validation_data=val_data, epochs=50)

model2.save_weights('/content/drive/MyDrive/model.weights.h5')

model2.load_weights('/content/drive/MyDrive/model.weights.h5')

#150 epochs
history = model2.fit(train_data, validation_data=val_data, epochs=50)

# Test data
history =model2.fit(test_data, epochs=50)

import matplotlib.pyplot as plt
# Assuming 'history' is the object returned by model.fit()
plt.figure(figsize=(10, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.grid(True)  # Add grid lines
plt.show()

# prompt: ive me code to generate plot between training loss  and validation loss with respect to each other,there should be grids in plot

import matplotlib.pyplot as plt

# Assuming 'history' is the object returned by model.fit()
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True)  # Add grid lines
plt.show()

# prompt: generate the plot between val loss and val dice coefficient

import matplotlib.pyplot as plt

# Assuming 'history' is the object returned by model.fit()
plt.figure(figsize=(10, 5))
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.plot(history.history['val_dice_coef'], label='Validation Dice Coefficient')
plt.xlabel('Epochs')
plt.ylabel('Value')
plt.title('Validation Loss vs. Validation Dice Coefficient')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

def plot_predictions(model1, test_images, test_masks, threshold=0.5):
    """
    Plots test images, their real masks, predicted masks, and accuracy for each row.

    Parameters:
    - model: Trained model for predictions.
    - test_images: List or array of test images (input to the model).
    - test_masks: List or array of corresponding ground truth masks.
    - threshold: Threshold for binary segmentation mask prediction.
    """
    num_samples = len(test_images)  # Number of test samples
    rows = num_samples
    cols = 3  # Original Image, Real Mask, Predicted Mask

    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))
    if rows == 1:
        axes = np.expand_dims(axes, 0)  # Ensure axes is 2D for a single sample

    for i, (image, real_mask) in enumerate(zip(test_images, test_masks)):
        # Predict the mask
        pred_mask = model.predict(np.expand_dims(image, axis=0))[0]
        pred_mask = (pred_mask > threshold).astype(np.uint8)  # Apply thresholding

        # Compute accuracy
        accuracy = np.mean(pred_mask == real_mask)

        # Plot Original Image
        axes[i, 0].imshow(image)
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis('off')

        # Plot Real Mask
        axes[i, 1].imshow(real_mask, cmap='gray')
        axes[i, 1].set_title("Real Mask")
        axes[i, 1].axis('off')

        # Plot Predicted Mask with Accuracy
        axes[i, 2].imshow(pred_mask, cmap='gray')
        axes[i, 2].set_title(f"Predicted Mask\nAccuracy: {accuracy:.2f}")
        axes[i, 2].axis('off')

    plt.tight_layout()

    plt.show()

plot_predictions(model2,X_test, Y_test)